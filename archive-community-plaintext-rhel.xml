<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite errors="0" failures="0" hostname="ip-172-31-47-19.us-west-2.compute.internal" name="pytest" skipped="0" tests="1" time="593.299" timestamp="2022-10-20T11:08:48.158426"><testcase classname="molecule.archive-community-plaintext-rhel.molecule.yml" name="test" time="593.239"><system-out>--------------------------------- Captured Out ---------------------------------
running: /usr/bin/python3 -m molecule test -s archive-community-plaintext-rhel -- (from /home/centos/repos/ansible_collections/confluent/platform)
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the 
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16 
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be 
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[DEPRECATION WARNING]: [defaults]callback_whitelist option, normalizing names 
to new standard, use callbacks_enabled instead. This feature will be removed 
from ansible-core in version 2.15. Deprecation warnings can be disabled by 
setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!
  RequestsDependencyWarning)
INFO     Found config file /home/centos/repos/ansible_collections/confluent/platform/.config/molecule/config.yml
INFO     archive-community-plaintext-rhel scenario test matrix: lint, dependency, cleanup, destroy, syntax, create, prepare, converge, side_effect, verify, cleanup, destroy
INFO     Performing prerun...
INFO     Set ANSIBLE_LIBRARY=/home/centos/.cache/ansible-compat/049b90/modules:plugins/modules:/home/centos/.ansible/plugins/modules:/usr/share/ansible/plugins/modules
INFO     Set ANSIBLE_COLLECTIONS_PATH=/home/centos/.cache/ansible-compat/049b90/collections:/home/centos/.ansible/collections:/home/centos/repos
INFO     Set ANSIBLE_ROLES_PATH=/home/centos/.cache/ansible-compat/049b90/roles:roles:/home/centos/.ansible/roles:/usr/share/ansible/roles:/etc/ansible/roles
INFO     Running ansible-galaxy collection install -v --force -p /home/centos/.cache/ansible-compat/049b90/collections .
INFO     Running archive-community-plaintext-rhel &gt; lint
INFO     Lint is disabled.
INFO     Running archive-community-plaintext-rhel &gt; dependency
INFO     Running ansible-galaxy collection install -v community.docker:&gt;=1.9.1
WARNING  Skipping, missing the requirements file.
WARNING  Skipping, missing the requirements file.
INFO     Running archive-community-plaintext-rhel &gt; cleanup
INFO     Sanity checks: 'docker'
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[WARNING]: running playbook inside collection confluent.platform

PLAY [Cleanup] *****************************************************************

TASK [Delete Tar Jar] **********************************************************
ok: [localhost]

TASK [Delete Tar CLI] **********************************************************
ok: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

INFO     Running archive-community-plaintext-rhel &gt; destroy
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.

PLAY [Destroy] *****************************************************************

TASK [Destroy molecule instance(s)] ********************************************
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
changed: [localhost] =&gt; (item=zookeeper1)
changed: [localhost] =&gt; (item=kafka-broker1)
changed: [localhost] =&gt; (item=schema-registry1)
changed: [localhost] =&gt; (item=kafka-rest1)
changed: [localhost] =&gt; (item=kafka-connect1)
changed: [localhost] =&gt; (item=ksql1)

TASK [Wait for instance(s) deletion to complete] *******************************
ok: [localhost] =&gt; (item=zookeeper1)
ok: [localhost] =&gt; (item=kafka-broker1)
ok: [localhost] =&gt; (item=schema-registry1)
ok: [localhost] =&gt; (item=kafka-rest1)
ok: [localhost] =&gt; (item=kafka-connect1)
ok: [localhost] =&gt; (item=ksql1)

TASK [Delete docker networks(s)] ***********************************************
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=14   changed=1    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0

INFO     Running archive-community-plaintext-rhel &gt; syntax
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[WARNING]: running playbook inside collection confluent.platform
[WARNING]: Could not match supplied host pattern, ignoring: control_center
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_replicator
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_parallel
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_serial
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_follower
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_leader
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_broker_parallel
[WARNING]: Could not match supplied host pattern, ignoring: kafka_broker_serial
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_broker_non_controller
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_broker_controller
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_parallel
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_serial
[WARNING]: Could not match supplied host pattern, ignoring: ksql_parallel
[WARNING]: Could not match supplied host pattern, ignoring: ksql_serial
[WARNING]: Could not match supplied host pattern, ignoring: kafka_rest_parallel
[WARNING]: Could not match supplied host pattern, ignoring: kafka_rest_serial
[WARNING]: Could not match supplied host pattern, ignoring:
control_center_parallel
[WARNING]: Could not match supplied host pattern, ignoring:
control_center_serial
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_replicator_parallel
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_replicator_serial

playbook: /home/centos/repos/ansible_collections/confluent/platform/molecule/collections_converge.yml
INFO     Running archive-community-plaintext-rhel &gt; create
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.

PLAY [Create] ******************************************************************

TASK [Log into a Docker registry] **********************************************
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
skipping: [localhost] =&gt; (item=None)
skipping: [localhost] =&gt; (item=None)
skipping: [localhost] =&gt; (item=None)
skipping: [localhost] =&gt; (item=None)
skipping: [localhost] =&gt; (item=None)
skipping: [localhost] =&gt; (item=None)
skipping: [localhost]

TASK [Check presence of custom Dockerfiles] ************************************
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['zookeeper'], 'hostname': 'zookeeper1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'zookeeper1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_broker'], 'hostname': 'kafka-broker1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-broker1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['schema_registry'], 'hostname': 'schema-registry1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'schema-registry1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_rest'], 'hostname': 'kafka-rest1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-rest1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_connect'], 'hostname': 'kafka-connect1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-connect1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['ksql'], 'hostname': 'ksql1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'ksql1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})

TASK [Create Dockerfiles from image names] *************************************
changed: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['zookeeper'], 'hostname': 'zookeeper1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'zookeeper1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_broker'], 'hostname': 'kafka-broker1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-broker1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['schema_registry'], 'hostname': 'schema-registry1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'schema-registry1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_rest'], 'hostname': 'kafka-rest1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-rest1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_connect'], 'hostname': 'kafka-connect1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-connect1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['ksql'], 'hostname': 'ksql1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'ksql1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})

TASK [Discover local Docker images] ********************************************
ok: [localhost] =&gt; (item={'diff': [], 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'src': '/home/centos/.ansible/tmp/ansible-tmp-1666264160.538263-14309-221748064784358/source', 'md5sum': '48fb212c7f6adf7ee16c93871066d585', 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'changed': True, 'uid': 1000, 'gid': 1000, 'owner': 'centos', 'group': 'centos', 'mode': '0600', 'state': 'file', 'secontext': 'unconfined_u:object_r:cache_home_t:s0', 'size': 106, 'invocation': {'module_args': {'src': '/home/centos/.ansible/tmp/ansible-tmp-1666264160.538263-14309-221748064784358/source', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'mode': '0600', 'follow': False, '_original_basename': 'Dockerfile-rhel-base.j2', 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'backup': False, 'force': True, 'unsafe_writes': False, 'content': None, 'validate': None, 'directory_mode': None, 'remote_src': None, 'local_follow': None, 'owner': None, 'group': None, 'seuser': None, 'serole': None, 'selevel': None, 'setype': None, 'attributes': None}}, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['zookeeper'], 'hostname': 'zookeeper1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'zookeeper1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item', 'i': 0, 'ansible_index_var': 'i'})
ok: [localhost] =&gt; (item={'diff': {'before': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}, 'after': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}}, 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'changed': False, 'uid': 1000, 'gid': 1000, 'owner': 'centos', 'group': 'centos', 'mode': '0600', 'state': 'file', 'secontext': 'unconfined_u:object_r:cache_home_t:s0', 'size': 106, 'invocation': {'module_args': {'mode': '0600', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', '_original_basename': 'Dockerfile-rhel-base.j2', 'recurse': False, 'state': 'file', 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'force': False, 'follow': True, 'modification_time_format': '%Y%m%d%H%M.%S', 'access_time_format': '%Y%m%d%H%M.%S', 'unsafe_writes': False, '_diff_peek': None, 'src': None, 'modification_time': None, 'access_time': None, 'owner': None, 'group': None, 'seuser': None, 'serole': None, 'selevel': None, 'setype': None, 'attributes': None}}, 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_broker'], 'hostname': 'kafka-broker1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-broker1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item', 'i': 1, 'ansible_index_var': 'i'})
ok: [localhost] =&gt; (item={'diff': {'before': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}, 'after': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}}, 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'changed': False, 'uid': 1000, 'gid': 1000, 'owner': 'centos', 'group': 'centos', 'mode': '0600', 'state': 'file', 'secontext': 'unconfined_u:object_r:cache_home_t:s0', 'size': 106, 'invocation': {'module_args': {'mode': '0600', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', '_original_basename': 'Dockerfile-rhel-base.j2', 'recurse': False, 'state': 'file', 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'force': False, 'follow': True, 'modification_time_format': '%Y%m%d%H%M.%S', 'access_time_format': '%Y%m%d%H%M.%S', 'unsafe_writes': False, '_diff_peek': None, 'src': None, 'modification_time': None, 'access_time': None, 'owner': None, 'group': None, 'seuser': None, 'serole': None, 'selevel': None, 'setype': None, 'attributes': None}}, 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['schema_registry'], 'hostname': 'schema-registry1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'schema-registry1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item', 'i': 2, 'ansible_index_var': 'i'})
ok: [localhost] =&gt; (item={'diff': {'before': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}, 'after': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}}, 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'changed': False, 'uid': 1000, 'gid': 1000, 'owner': 'centos', 'group': 'centos', 'mode': '0600', 'state': 'file', 'secontext': 'unconfined_u:object_r:cache_home_t:s0', 'size': 106, 'invocation': {'module_args': {'mode': '0600', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', '_original_basename': 'Dockerfile-rhel-base.j2', 'recurse': False, 'state': 'file', 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'force': False, 'follow': True, 'modification_time_format': '%Y%m%d%H%M.%S', 'access_time_format': '%Y%m%d%H%M.%S', 'unsafe_writes': False, '_diff_peek': None, 'src': None, 'modification_time': None, 'access_time': None, 'owner': None, 'group': None, 'seuser': None, 'serole': None, 'selevel': None, 'setype': None, 'attributes': None}}, 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_rest'], 'hostname': 'kafka-rest1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-rest1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item', 'i': 3, 'ansible_index_var': 'i'})
ok: [localhost] =&gt; (item={'diff': {'before': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}, 'after': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}}, 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'changed': False, 'uid': 1000, 'gid': 1000, 'owner': 'centos', 'group': 'centos', 'mode': '0600', 'state': 'file', 'secontext': 'unconfined_u:object_r:cache_home_t:s0', 'size': 106, 'invocation': {'module_args': {'mode': '0600', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', '_original_basename': 'Dockerfile-rhel-base.j2', 'recurse': False, 'state': 'file', 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'force': False, 'follow': True, 'modification_time_format': '%Y%m%d%H%M.%S', 'access_time_format': '%Y%m%d%H%M.%S', 'unsafe_writes': False, '_diff_peek': None, 'src': None, 'modification_time': None, 'access_time': None, 'owner': None, 'group': None, 'seuser': None, 'serole': None, 'selevel': None, 'setype': None, 'attributes': None}}, 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_connect'], 'hostname': 'kafka-connect1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-connect1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item', 'i': 4, 'ansible_index_var': 'i'})
ok: [localhost] =&gt; (item={'diff': {'before': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}, 'after': {'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible'}}, 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'changed': False, 'uid': 1000, 'gid': 1000, 'owner': 'centos', 'group': 'centos', 'mode': '0600', 'state': 'file', 'secontext': 'unconfined_u:object_r:cache_home_t:s0', 'size': 106, 'invocation': {'module_args': {'mode': '0600', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', '_original_basename': 'Dockerfile-rhel-base.j2', 'recurse': False, 'state': 'file', 'path': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'force': False, 'follow': True, 'modification_time_format': '%Y%m%d%H%M.%S', 'access_time_format': '%Y%m%d%H%M.%S', 'unsafe_writes': False, '_diff_peek': None, 'src': None, 'modification_time': None, 'access_time': None, 'owner': None, 'group': None, 'seuser': None, 'serole': None, 'selevel': None, 'setype': None, 'attributes': None}}, 'checksum': '2ebf411852103ed5df8d41e329966a76bae1b606', 'dest': '/home/centos/.cache/molecule/platform/archive-community-plaintext-rhel/Dockerfile_geerlingguy_docker_centos7_ansible', 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['ksql'], 'hostname': 'ksql1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'ksql1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item', 'i': 5, 'ansible_index_var': 'i'})

TASK [Build an Ansible compatible image (new)] *********************************
changed: [localhost] =&gt; (item=molecule_local/geerlingguy/docker-centos7-ansible)
ok: [localhost] =&gt; (item=molecule_local/geerlingguy/docker-centos7-ansible)
ok: [localhost] =&gt; (item=molecule_local/geerlingguy/docker-centos7-ansible)
ok: [localhost] =&gt; (item=molecule_local/geerlingguy/docker-centos7-ansible)
ok: [localhost] =&gt; (item=molecule_local/geerlingguy/docker-centos7-ansible)
ok: [localhost] =&gt; (item=molecule_local/geerlingguy/docker-centos7-ansible)

TASK [Create docker network(s)] ************************************************
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/create_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/create_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/create_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/create_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/create_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/create_network.yml for localhost =&gt; (item=confluent)

TASK [Check if network exist] **************************************************
ok: [localhost]

TASK [Create docker network(s)] ************************************************
changed: [localhost]

TASK [Check if network exist] **************************************************
ok: [localhost]

TASK [Create docker network(s)] ************************************************
skipping: [localhost]

TASK [Check if network exist] **************************************************
ok: [localhost]

TASK [Create docker network(s)] ************************************************
skipping: [localhost]

TASK [Check if network exist] **************************************************
ok: [localhost]

TASK [Create docker network(s)] ************************************************
skipping: [localhost]

TASK [Check if network exist] **************************************************
ok: [localhost]

TASK [Create docker network(s)] ************************************************
skipping: [localhost]

TASK [Check if network exist] **************************************************
ok: [localhost]

TASK [Create docker network(s)] ************************************************
skipping: [localhost]

TASK [Determine the CMD directives] ********************************************
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['zookeeper'], 'hostname': 'zookeeper1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'zookeeper1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_broker'], 'hostname': 'kafka-broker1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-broker1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['schema_registry'], 'hostname': 'schema-registry1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'schema-registry1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_rest'], 'hostname': 'kafka-rest1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-rest1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_connect'], 'hostname': 'kafka-connect1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-connect1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})
ok: [localhost] =&gt; (item={'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['ksql'], 'hostname': 'ksql1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'ksql1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']})

TASK [Create molecule instance(s)] *********************************************
changed: [localhost] =&gt; (item=zookeeper1)
changed: [localhost] =&gt; (item=kafka-broker1)
changed: [localhost] =&gt; (item=schema-registry1)
changed: [localhost] =&gt; (item=kafka-rest1)
changed: [localhost] =&gt; (item=kafka-connect1)
changed: [localhost] =&gt; (item=ksql1)

TASK [Wait for instance(s) creation to complete] *******************************
changed: [localhost] =&gt; (item={'started': 1, 'finished': 0, 'ansible_job_id': '485580935641.15785', 'results_file': '/home/centos/.ansible_async/485580935641.15785', 'changed': True, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['zookeeper'], 'hostname': 'zookeeper1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'zookeeper1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item'})
changed: [localhost] =&gt; (item={'started': 1, 'finished': 0, 'ansible_job_id': '220785559188.15810', 'results_file': '/home/centos/.ansible_async/220785559188.15810', 'changed': True, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_broker'], 'hostname': 'kafka-broker1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-broker1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item'})
changed: [localhost] =&gt; (item={'started': 1, 'finished': 0, 'ansible_job_id': '749976374068.15838', 'results_file': '/home/centos/.ansible_async/749976374068.15838', 'changed': True, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['schema_registry'], 'hostname': 'schema-registry1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'schema-registry1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item'})
changed: [localhost] =&gt; (item={'started': 1, 'finished': 0, 'ansible_job_id': '138316363027.15990', 'results_file': '/home/centos/.ansible_async/138316363027.15990', 'changed': True, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_rest'], 'hostname': 'kafka-rest1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-rest1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item'})
changed: [localhost] =&gt; (item={'started': 1, 'finished': 0, 'ansible_job_id': '708124943698.16159', 'results_file': '/home/centos/.ansible_async/708124943698.16159', 'changed': True, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['kafka_connect'], 'hostname': 'kafka-connect1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'kafka-connect1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item'})
changed: [localhost] =&gt; (item={'started': 1, 'finished': 0, 'ansible_job_id': '474274106418.16345', 'results_file': '/home/centos/.ansible_async/474274106418.16345', 'changed': True, 'failed': False, 'item': {'command': '', 'dockerfile': '../Dockerfile-rhel-base.j2', 'groups': ['ksql'], 'hostname': 'ksql1.confluent', 'image': 'geerlingguy/docker-centos7-ansible', 'name': 'ksql1', 'networks': [{'name': 'confluent'}], 'privileged': True, 'volumes': ['/sys/fs/cgroup:/sys/fs/cgroup:ro']}, 'ansible_loop_var': 'item'})
[DEPRECATION WARNING]: Please note that the default value for `network_mode`
will change from not specified (which is equal to `default`) to the name of the
 first network in `networks` if `networks` has at least one entry and
`networks_cli_compatible` is `true`. You can change the behavior now by
explicitly setting `network_mode` to the name of the first network in
`networks`, and remove this warning by setting `network_mode` to `default`.
Please make sure that the value you set to `network_mode` equals the inspection
 result for existing containers, otherwise the module will recreate them. You
can find out the correct value by running "docker inspect --format
'{{.HostConfig.NetworkMode}}' &lt;container_name&gt;". This feature will be removed
from community.docker in version 2.0.0. Deprecation warnings can be disabled by
 setting deprecation_warnings=False in ansible.cfg.

PLAY RECAP *********************************************************************
localhost                  : ok=20   changed=5    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0

INFO     Running archive-community-plaintext-rhel &gt; prepare
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[WARNING]: running playbook inside collection confluent.platform

PLAY [Prepare] *****************************************************************

TASK [Download Tar] ************************************************************
changed: [localhost]

TASK [Download CLI tar] ********************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

INFO     Running archive-community-plaintext-rhel &gt; converge
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[WARNING]: running playbook inside collection confluent.platform
[WARNING]: Could not match supplied host pattern, ignoring: control_center
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_replicator

PLAY [Host Prerequisites] ******************************************************

TASK [Create Certificate Authority and Copy to Ansible Host] *******************
skipping: [zookeeper1]

TASK [confluent.platform.common : Confirm Hash Merging Enabled] ****************
ok: [zookeeper1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [ksql1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-broker1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [schema-registry1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-rest1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-connect1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Verify Ansible version] **********************
ok: [zookeeper1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-broker1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [schema-registry1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-connect1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [ksql1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-rest1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Gather OS Facts] *****************************
ok: [kafka-connect1]
ok: [zookeeper1]
ok: [ksql1]
ok: [schema-registry1]
ok: [kafka-rest1]
ok: [kafka-broker1]

TASK [confluent.platform.common : Host Validations] ****************************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/common/tasks/host_validations.yml for zookeeper1, kafka-broker1, schema-registry1, kafka-connect1, ksql1, kafka-rest1

TASK [confluent.platform.common : Confirm Rhel Version Supported] **************
ok: [zookeeper1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-broker1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [schema-registry1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-connect1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [ksql1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-rest1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Confirm Ubuntu Version Supported] ************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Confirm Debian Version Supported] ************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Check Internet Access for Confluent Packages/Archive] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Fail Provisioning because No Network Connectivity] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Check /tmp directory details] ****************
ok: [kafka-broker1]
ok: [zookeeper1]
ok: [schema-registry1]
ok: [ksql1]
ok: [kafka-connect1]
ok: [kafka-rest1]

TASK [confluent.platform.common : Assert /tmp is accessible] *******************
ok: [zookeeper1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-broker1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [schema-registry1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-connect1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [ksql1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
ok: [kafka-rest1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Validate disk space usage] *******************
skipping: [zookeeper1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hosts', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [zookeeper1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hostname', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [zookeeper1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/resolv.conf', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [zookeeper1]
skipping: [kafka-broker1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hosts', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-broker1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hostname', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-broker1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/resolv.conf', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-broker1]
skipping: [schema-registry1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hosts', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [schema-registry1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hostname', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [schema-registry1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/resolv.conf', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [schema-registry1]
skipping: [kafka-connect1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hosts', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-connect1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hostname', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-connect1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/resolv.conf', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-connect1]
skipping: [ksql1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hosts', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [ksql1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hostname', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [ksql1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/resolv.conf', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [ksql1]
skipping: [kafka-rest1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hosts', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-rest1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/hostname', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-rest1] =&gt; (item={'block_used': 1068436, 'uuid': 'N/A', 'size_total': 42938118144, 'block_total': 10482939, 'mount': '/etc/resolv.conf', 'block_available': 9414503, 'size_available': 38561804288, 'fstype': 'xfs', 'inode_total': 20970944, 'options': 'rw,seclabel,relatime,attr2,inode64,noquota,bind', 'device': '/dev/nvme0n1p1', 'inode_used': 172853, 'block_size': 4096, 'inode_available': 20798091})
skipping: [kafka-rest1]

TASK [confluent.platform.common : Retrieve SSL key hash] ***********************
skipping: [zookeeper1] =&gt; (item=zookeeper)
skipping: [kafka-broker1] =&gt; (item=kafka_broker)
skipping: [schema-registry1] =&gt; (item=schema_registry)
skipping: [kafka-connect1] =&gt; (item=kafka_connect)
skipping: [ksql1] =&gt; (item=ksql)
skipping: [kafka-rest1] =&gt; (item=kafka_rest)

TASK [confluent.platform.common : Retrieve SSL cert hash] **********************
skipping: [zookeeper1] =&gt; (item=zookeeper)
skipping: [kafka-broker1] =&gt; (item=kafka_broker)
skipping: [schema-registry1] =&gt; (item=schema_registry)
skipping: [kafka-connect1] =&gt; (item=kafka_connect)
skipping: [ksql1] =&gt; (item=ksql)
skipping: [kafka-rest1] =&gt; (item=kafka_rest)

TASK [confluent.platform.common : Assert SSL key hash matches SSL cert hash] ***
skipping: [zookeeper1] =&gt; (item=zookeeper)
skipping: [kafka-broker1] =&gt; (item=kafka_broker)
skipping: [schema-registry1] =&gt; (item=schema_registry)
skipping: [kafka-connect1] =&gt; (item=kafka_connect)
skipping: [ksql1] =&gt; (item=ksql)
skipping: [kafka-rest1] =&gt; (item=kafka_rest)

TASK [confluent.platform.common : Validate enough free memory for Zookeeper hosts] ***
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
ok: [zookeeper1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Validate enough free memory for Kafka Broker hosts] ***
skipping: [zookeeper1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
ok: [kafka-broker1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}
skipping: [kafka-rest1]

TASK [confluent.platform.common : Validate enough free memory for Kafka Connect hosts] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [ksql1]
skipping: [kafka-rest1]
ok: [kafka-connect1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Validate enough free memory for Schema Registry hosts] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]
ok: [schema-registry1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Validate enough free memory for KSQL hosts] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [kafka-rest1]
ok: [ksql1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Validate enough free memory for Rest Proxy hosts] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
ok: [kafka-rest1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [confluent.platform.common : Validate enough free memory for Control Center hosts] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Validate enough free memory for Kafka Connect Replicator hosts] ***
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Red Hat Repo Setup and Java Installation] ****
included: /home/centos/repos/ansible_collections/confluent/platform/roles/common/tasks/redhat.yml for zookeeper1, kafka-broker1, schema-registry1, kafka-connect1, ksql1, kafka-rest1

TASK [confluent.platform.common : Add Confluent Repo file] *********************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Add Custom Repo file] ************************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : yum-clean-all] *******************************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Install Java] ********************************
ok: [kafka-rest1]
ok: [kafka-broker1]
ok: [zookeeper1]
ok: [ksql1]
ok: [kafka-connect1]
ok: [schema-registry1]

TASK [confluent.platform.common : Install OpenSSL and Unzip] *******************
changed: [zookeeper1]
changed: [kafka-rest1]
changed: [schema-registry1]
changed: [kafka-broker1]
changed: [kafka-connect1]
changed: [ksql1]

TASK [confluent.platform.common : Ubuntu Repo Setup and Java Installation] *****
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Debian Repo Setup and Java Installation] *****
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Create Confluent Platform install directory] ***
changed: [kafka-broker1]
changed: [ksql1]
changed: [kafka-rest1]
changed: [schema-registry1]
changed: [kafka-connect1]
changed: [zookeeper1]

TASK [confluent.platform.common : Expand remote Confluent Platform archive] ****
changed: [ksql1]
changed: [kafka-broker1]
changed: [zookeeper1]
changed: [schema-registry1]
changed: [kafka-connect1]
changed: [kafka-rest1]

TASK [confluent.platform.common : Create Jolokia directory] ********************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Copy Jolokia Jar] ****************************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Download Jolokia Jar] ************************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Create Prometheus install directory] *********
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Copy Prometheus Jar] *************************
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Download Prometheus JMX Exporter Jar] ********
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Install Confluent CLI] ***********************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/common/tasks/confluent_cli.yml for zookeeper1, kafka-broker1, kafka-connect1, schema-registry1, ksql1, kafka-rest1

TASK [confluent.platform.common : Confluent CLI system check] ******************
ok: [zookeeper1]
ok: [kafka-broker1]
ok: [schema-registry1]
ok: [kafka-connect1]
ok: [ksql1]
ok: [kafka-rest1]

TASK [confluent.platform.common : Confluent CLI architecture check] ************
ok: [zookeeper1]
ok: [kafka-broker1]
ok: [schema-registry1]
ok: [kafka-connect1]
ok: [ksql1]
ok: [kafka-rest1]

TASK [confluent.platform.common : Directory name for the Confluent CLI version] ***
ok: [zookeeper1]
ok: [kafka-broker1]
ok: [schema-registry1]
ok: [kafka-connect1]
ok: [ksql1]
ok: [kafka-rest1]

TASK [confluent.platform.common : Confluent CLI create base path] **************
changed: [zookeeper1]
changed: [kafka-broker1]
changed: [schema-registry1]
changed: [kafka-connect1]
changed: [ksql1]
changed: [kafka-rest1]

TASK [confluent.platform.common : Expand remote Confluent CLI archive] *********
changed: [ksql1]
changed: [kafka-broker1]
changed: [schema-registry1]
changed: [kafka-connect1]
changed: [zookeeper1]
changed: [kafka-rest1]

TASK [confluent.platform.common : Download Confluent CLI - Custom URL] *********
skipping: [zookeeper1]
skipping: [kafka-broker1]
skipping: [schema-registry1]
skipping: [kafka-connect1]
skipping: [ksql1]
skipping: [kafka-rest1]

TASK [confluent.platform.common : Delete any existing symlink for confluent cli] ***
ok: [kafka-broker1]
ok: [zookeeper1]
ok: [ksql1]
ok: [kafka-connect1]
ok: [schema-registry1]
ok: [kafka-rest1]

TASK [confluent.platform.common : Confluent CLI create symlink in /usr/local/bin/confluent] ***
changed: [zookeeper1]
changed: [kafka-broker1]
changed: [schema-registry1]
changed: [ksql1]
changed: [kafka-connect1]
changed: [kafka-rest1]

TASK [confluent.platform.common : set_fact] ************************************
ok: [zookeeper1]
ok: [kafka-broker1]
ok: [schema-registry1]
ok: [kafka-connect1]
ok: [ksql1]
ok: [kafka-rest1]

PLAY [Zookeeper Status Finding] ************************************************

TASK [Populate service facts] **************************************************
ok: [zookeeper1]

TASK [Determine Installation Pattern - Parallel or Serial] *********************
ok: [zookeeper1]

TASK [Group Hosts by Installation Pattern] *************************************
ok: [zookeeper1]

PLAY [Zookeeper Parallel Provisioning] *****************************************

TASK [include_role : common] ***************************************************
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Gather OS Facts] **************************
ok: [zookeeper1] =&gt; (item=ansible_os_family)
ok: [zookeeper1] =&gt; (item=ansible_fqdn)

TASK [Stop Service and Remove Packages on Version Change] **********************
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Install the Zookeeper Packages] ***********
skipping: [zookeeper1] =&gt; (item=confluent-common)
skipping: [zookeeper1] =&gt; (item=confluent-rest-utils)
skipping: [zookeeper1] =&gt; (item=confluent-metadata-service)
skipping: [zookeeper1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [zookeeper1] =&gt; (item=confluent-kafka-rest)
skipping: [zookeeper1] =&gt; (item=confluent-server-rest)
skipping: [zookeeper1] =&gt; (item=confluent-telemetry)
skipping: [zookeeper1] =&gt; (item=confluent-kafka)

TASK [confluent.platform.zookeeper : Install the Zookeeper Packages] ***********
skipping: [zookeeper1] =&gt; (item=confluent-common)
skipping: [zookeeper1] =&gt; (item=confluent-rest-utils)
skipping: [zookeeper1] =&gt; (item=confluent-metadata-service)
skipping: [zookeeper1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [zookeeper1] =&gt; (item=confluent-kafka-rest)
skipping: [zookeeper1] =&gt; (item=confluent-server-rest)
skipping: [zookeeper1] =&gt; (item=confluent-telemetry)
skipping: [zookeeper1] =&gt; (item=confluent-kafka)

TASK [confluent.platform.zookeeper : Create Zookeeper Group] *******************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Check if Zookeeper User Exists] ***********
ok: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper User] ********************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Copy Zookeeper Service from archive file to system] ***
changed: [zookeeper1]

TASK [include_role : ssl] ******************************************************
skipping: [zookeeper1]

TASK [Configure Kerberos] ******************************************************
skipping: [zookeeper1]

TASK [Copy Custom Zookeeper Files] *********************************************
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Set Zookeeper Data Dir Ownership] *********
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Set Ownership of Data Dir Files] **********
ok: [zookeeper1]

TASK [confluent.platform.zookeeper : Set Zookeeper Transaction Log Data Dir Ownership] ***
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Set Ownership of Transaction Log Data Dir Files] ***
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper myid File] ***************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper Config directory] ********
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper Config] ******************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Log Directory] *********************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Create log4j Directory] *******************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper log4j config] ************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Create logredactor rule file directory] ***
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Copy logredactor rule file from control node to component node] ***
skipping: [zookeeper1]

TASK [Configure logredactor] ***************************************************
skipping: [zookeeper1] =&gt; (item={'logger_name': 'log4j.rootLogger', 'appenderRefs': 'zkAppender'})

TASK [confluent.platform.zookeeper : Restart zookeeper] ************************
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper Jolokia Config] **********
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Zookeeper Jaas config] *************
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Deploy JMX Exporter Config File] **********
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Create Service Override Directory] ********
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Write Service Overrides] ******************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Certs were Updated - Trigger Restart] *****
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : meta] *************************************

RUNNING HANDLER [confluent.platform.zookeeper : restart zookeeper] *************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/zookeeper/tasks/restart_and_wait.yml for zookeeper1

RUNNING HANDLER [confluent.platform.zookeeper : Restart Zookeeper] *************
changed: [zookeeper1]

RUNNING HANDLER [confluent.platform.zookeeper : Startup Delay] *****************
ok: [zookeeper1]

TASK [confluent.platform.zookeeper : Zookeeper Service Started] ****************
changed: [zookeeper1]

TASK [confluent.platform.zookeeper : Zookeeper Health Check] *******************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/zookeeper/tasks/health_check.yml for zookeeper1

TASK [confluent.platform.zookeeper : Wait for Zookeeper Status] ****************
ok: [zookeeper1]

TASK [confluent.platform.zookeeper : Wait for Zookeeper Quorum] ****************
ok: [zookeeper1]

TASK [confluent.platform.zookeeper : Fetch Files for Debugging Failure] ********
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Fail Provisioning] ************************
skipping: [zookeeper1]

TASK [confluent.platform.zookeeper : Delete temporary keys/certs when keystore and trustore is provided] ***
skipping: [zookeeper1] =&gt; (item=/var/ssl/private/ca.crt)
skipping: [zookeeper1] =&gt; (item=/var/ssl/private/zookeeper.crt)
skipping: [zookeeper1] =&gt; (item=/var/ssl/private/zookeeper.key)
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_serial

PLAY [Zookeeper Serial Ordering] ***********************************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_follower

PLAY [Zookeeper Followers Provisioning] ****************************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring: zookeeper_leader

PLAY [Zookeeper Leader Provisioning] *******************************************
skipping: no hosts matched

PLAY [Kafka Broker Status Finding] *********************************************

TASK [Populate service facts] **************************************************
ok: [kafka-broker1]

TASK [Determine Installation Pattern - Parallel or Serial] *********************
ok: [kafka-broker1]

TASK [Group Hosts by Installation Pattern] *************************************
ok: [kafka-broker1]

PLAY [Kafka Broker Parallel Provisioning] **************************************

TASK [include_role : common] ***************************************************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Gather OS Facts] ***********************
ok: [kafka-broker1] =&gt; (item=ansible_os_family)
ok: [kafka-broker1] =&gt; (item=ansible_fqdn)
ok: [kafka-broker1] =&gt; (item=ansible_distribution)

TASK [confluent.platform.kafka_broker : Assert that datadir is not present in the inventory] ***
ok: [kafka-broker1] =&gt; (item=kafka-broker1) =&gt; {
    "ansible_loop_var": "item",
    "changed": false,
    "item": "kafka-broker1",
    "msg": "All assertions passed"
}

TASK [confluent.platform.kafka_broker : Assert log.dirs Property not Misconfigured] ***
ok: [kafka-broker1] =&gt; {
    "changed": false,
    "msg": "All assertions passed"
}

TASK [Stop Service and Remove Packages on Version Change] **********************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Install the Kafka Broker Packages] *****
skipping: [kafka-broker1] =&gt; (item=confluent-common)
skipping: [kafka-broker1] =&gt; (item=confluent-rest-utils)
skipping: [kafka-broker1] =&gt; (item=confluent-metadata-service)
skipping: [kafka-broker1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [kafka-broker1] =&gt; (item=confluent-kafka-rest)
skipping: [kafka-broker1] =&gt; (item=confluent-server-rest)
skipping: [kafka-broker1] =&gt; (item=confluent-telemetry)
skipping: [kafka-broker1] =&gt; (item=confluent-kafka)
skipping: [kafka-broker1] =&gt; (item=confluent-rebalancer)
skipping: [kafka-broker1] =&gt; (item=confluent-security)

TASK [confluent.platform.kafka_broker : Install the Kafka Broker Packages] *****
skipping: [kafka-broker1] =&gt; (item=confluent-common)
skipping: [kafka-broker1] =&gt; (item=confluent-rest-utils)
skipping: [kafka-broker1] =&gt; (item=confluent-metadata-service)
skipping: [kafka-broker1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [kafka-broker1] =&gt; (item=confluent-kafka-rest)
skipping: [kafka-broker1] =&gt; (item=confluent-server-rest)
skipping: [kafka-broker1] =&gt; (item=confluent-telemetry)
skipping: [kafka-broker1] =&gt; (item=confluent-kafka)
skipping: [kafka-broker1] =&gt; (item=confluent-rebalancer)
skipping: [kafka-broker1] =&gt; (item=confluent-security)

TASK [confluent.platform.kafka_broker : Kafka Broker group] ********************
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Check if Kafka Broker User Exists] *****
ok: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Kafka Broker user] **************
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Copy Kafka Broker Service from archive file to system] ***
changed: [kafka-broker1]

TASK [include_role : ssl] ******************************************************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : include_tasks] *************************
skipping: [kafka-broker1]

TASK [Configure Kerberos] ******************************************************
skipping: [kafka-broker1]

TASK [Copy Custom Kafka Files] *************************************************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Set Permissions on /var/lib/kafka] *****
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Set Permissions on Data Dirs] **********
changed: [kafka-broker1] =&gt; (item=/var/lib/kafka/data)

TASK [confluent.platform.kafka_broker : Set Permissions on Data Dir files] *****
ok: [kafka-broker1] =&gt; (item=/var/lib/kafka/data)

TASK [confluent.platform.kafka_broker : Create Kafka Broker Config directory] ***
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Kafka Broker Config] ************
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Kafka Broker Client Config] *****
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Zookeeper TLS Client Config] ****
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Logs Directory] *****************
changed: [kafka-broker1]

TASK [Update Kafka log4j Config for Log Cleanup] *******************************

TASK [confluent.platform.common : Replace rootLogger] **************************
ok: [kafka-broker1]

TASK [confluent.platform.common : Replace DailyRollingFileAppender with RollingFileAppender] ***
changed: [kafka-broker1]

TASK [confluent.platform.common : Remove Key log4j.appender.X.DatePattern] *****
changed: [kafka-broker1]

TASK [confluent.platform.common : Register Appenders] **************************
ok: [kafka-broker1]

TASK [confluent.platform.common : Add Max Size Properties] *********************
changed: [kafka-broker1] =&gt; (item=['kafkaAppender', 'Append=true'])
changed: [kafka-broker1] =&gt; (item=['kafkaAppender', 'MaxBackupIndex=10'])
changed: [kafka-broker1] =&gt; (item=['kafkaAppender', 'MaxFileSize=100MB'])
changed: [kafka-broker1] =&gt; (item=['stateChangeAppender', 'Append=true'])
changed: [kafka-broker1] =&gt; (item=['stateChangeAppender', 'MaxBackupIndex=10'])
changed: [kafka-broker1] =&gt; (item=['stateChangeAppender', 'MaxFileSize=100MB'])
changed: [kafka-broker1] =&gt; (item=['requestAppender', 'Append=true'])
changed: [kafka-broker1] =&gt; (item=['requestAppender', 'MaxBackupIndex=10'])
changed: [kafka-broker1] =&gt; (item=['requestAppender', 'MaxFileSize=100MB'])
changed: [kafka-broker1] =&gt; (item=['cleanerAppender', 'Append=true'])
changed: [kafka-broker1] =&gt; (item=['cleanerAppender', 'MaxBackupIndex=10'])
changed: [kafka-broker1] =&gt; (item=['cleanerAppender', 'MaxFileSize=100MB'])
changed: [kafka-broker1] =&gt; (item=['controllerAppender', 'Append=true'])
changed: [kafka-broker1] =&gt; (item=['controllerAppender', 'MaxBackupIndex=10'])
changed: [kafka-broker1] =&gt; (item=['controllerAppender', 'MaxFileSize=100MB'])
changed: [kafka-broker1] =&gt; (item=['authorizerAppender', 'Append=true'])
changed: [kafka-broker1] =&gt; (item=['authorizerAppender', 'MaxBackupIndex=10'])
changed: [kafka-broker1] =&gt; (item=['authorizerAppender', 'MaxFileSize=100MB'])

TASK [confluent.platform.kafka_broker : Set Permissions on Log4j Conf] *********
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create logredactor rule file directory] ***
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Copy logredactor rule file from control node to component node] ***
skipping: [kafka-broker1]

TASK [Configure logredactor] ***************************************************
skipping: [kafka-broker1] =&gt; (item={'logger_name': 'log4j.rootLogger', 'appenderRefs': 'kafkaAppender'})

TASK [confluent.platform.kafka_broker : Restart kafka broker] ******************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Kafka Broker Jolokia Config] ****
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Kafka Broker Jaas Config] *******
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Kafka Broker Password File] *****
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Zookeeper chroot] ***************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create SCRAM Users] ********************
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)

TASK [confluent.platform.kafka_broker : Create SCRAM 256 Users] ****************
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)
skipping: [kafka-broker1] =&gt; (item=None)

TASK [confluent.platform.kafka_broker : Deploy JMX Exporter Config File] *******
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create Service Override Directory] *****
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Write Service Overrides] ***************
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create sysctl directory on Debian distributions] ***
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create sysctl directory on Debian distributions] ***
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Tune virtual memory settings] **********
changed: [kafka-broker1] =&gt; (item={'key': 'vm.swappiness', 'value': 1})
changed: [kafka-broker1] =&gt; (item={'key': 'vm.dirty_background_ratio', 'value': 5})
changed: [kafka-broker1] =&gt; (item={'key': 'vm.dirty_ratio', 'value': 80})
changed: [kafka-broker1] =&gt; (item={'key': 'vm.max_map_count', 'value': 262144})

TASK [confluent.platform.kafka_broker : Certs were Updated - Trigger Restart] ***
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : meta] **********************************

RUNNING HANDLER [confluent.platform.kafka_broker : restart kafka] **************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_broker/tasks/restart_and_wait.yml for kafka-broker1

RUNNING HANDLER [confluent.platform.kafka_broker : Restart Kafka] **************
changed: [kafka-broker1]

RUNNING HANDLER [confluent.platform.kafka_broker : Startup Delay] **************
ok: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Encrypt secrets] ***********************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : meta] **********************************

TASK [confluent.platform.kafka_broker : Kafka Started] *************************
changed: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Wait for health checks to complete] ****
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_broker/tasks/health_check.yml for kafka-broker1

TASK [confluent.platform.kafka_broker : Get Topics with UnderReplicatedPartitions] ***
ok: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Get Topics with UnderReplicatedPartitions with Secrets Protection enabled] ***
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Wait for Metadata Service to start] ****
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Wait for Embedded Rest Proxy to start] ***
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Fetch Files for Debugging Failure] *****
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Fail Provisioning] *********************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Register Cluster] **********************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Create RBAC Rolebindings] **************
skipping: [kafka-broker1]

TASK [confluent.platform.kafka_broker : Delete temporary keys/certs when keystore and trustore is provided] ***
skipping: [kafka-broker1] =&gt; (item=/var/ssl/private/ca.crt)
skipping: [kafka-broker1] =&gt; (item=/var/ssl/private/kafka_broker.crt)
skipping: [kafka-broker1] =&gt; (item=/var/ssl/private/kafka_broker.key)
[WARNING]: Could not match supplied host pattern, ignoring: kafka_broker_serial

PLAY [Kafka Broker Serial Ordering] ********************************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_broker_non_controller

PLAY [Kafka Broker Non Controllers Provisioning] *******************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_broker_controller

PLAY [Kafka Broker Controller Provisioning] ************************************
skipping: no hosts matched

PLAY [Schema Registry Provisioning] ********************************************

TASK [include_role : common] ***************************************************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Gather OS Facts] ********************
ok: [schema-registry1] =&gt; (item=ansible_os_family)
ok: [schema-registry1] =&gt; (item=ansible_fqdn)

TASK [Stop Service and Remove Packages on Version Change] **********************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Install the Schema Registry Packages] ***
skipping: [schema-registry1] =&gt; (item=confluent-common)
skipping: [schema-registry1] =&gt; (item=confluent-rest-utils)
skipping: [schema-registry1] =&gt; (item=confluent-metadata-service)
skipping: [schema-registry1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [schema-registry1] =&gt; (item=confluent-kafka-rest)
skipping: [schema-registry1] =&gt; (item=confluent-server-rest)
skipping: [schema-registry1] =&gt; (item=confluent-telemetry)
skipping: [schema-registry1] =&gt; (item=confluent-kafka)
skipping: [schema-registry1] =&gt; (item=confluent-schema-registry)
skipping: [schema-registry1] =&gt; (item=confluent-security)
skipping: [schema-registry1] =&gt; (item=confluent-schema-registry-plugins)

TASK [confluent.platform.schema_registry : Install the Schema Registry Packages] ***
skipping: [schema-registry1] =&gt; (item=confluent-common)
skipping: [schema-registry1] =&gt; (item=confluent-rest-utils)
skipping: [schema-registry1] =&gt; (item=confluent-metadata-service)
skipping: [schema-registry1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [schema-registry1] =&gt; (item=confluent-kafka-rest)
skipping: [schema-registry1] =&gt; (item=confluent-server-rest)
skipping: [schema-registry1] =&gt; (item=confluent-telemetry)
skipping: [schema-registry1] =&gt; (item=confluent-kafka)
skipping: [schema-registry1] =&gt; (item=confluent-schema-registry)
skipping: [schema-registry1] =&gt; (item=confluent-security)
skipping: [schema-registry1] =&gt; (item=confluent-schema-registry-plugins)

TASK [confluent.platform.schema_registry : Schema Registry Group] **************
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Check if Schema Registry User Exists] ***
ok: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Schema Registry User] ********
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Copy Schema Registry Service from archive file to system] ***
changed: [schema-registry1]

TASK [include_role : ssl] ******************************************************
skipping: [schema-registry1]

TASK [Configure Kerberos] ******************************************************
skipping: [schema-registry1]

TASK [Copy Custom Schema Registry Files] ***************************************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Configure RBAC] *********************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Schema Registry Config directory] ***
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Schema Registry Config] ******
changed: [schema-registry1]

TASK [Create Schema Registry Config with Secrets Protection] *******************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Logs Directory] **************
changed: [schema-registry1]

TASK [Update log4j Config for Log Cleanup] *************************************

TASK [confluent.platform.common : Replace rootLogger] **************************
ok: [schema-registry1]

TASK [confluent.platform.common : Replace DailyRollingFileAppender with RollingFileAppender] ***
ok: [schema-registry1]

TASK [confluent.platform.common : Remove Key log4j.appender.X.DatePattern] *****
ok: [schema-registry1]

TASK [confluent.platform.common : Register Appenders] **************************
ok: [schema-registry1]

TASK [confluent.platform.common : Add Max Size Properties] *********************
changed: [schema-registry1] =&gt; (item=['file', 'Append=true'])
changed: [schema-registry1] =&gt; (item=['file', 'MaxBackupIndex=10'])
changed: [schema-registry1] =&gt; (item=['file', 'MaxFileSize=100MB'])

TASK [confluent.platform.schema_registry : Set Permissions on Log4j Conf] ******
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Create logredactor rule file directory] ***
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Copy logredactor rule file from control node to component node] ***
skipping: [schema-registry1]

TASK [Configure logredactor] ***************************************************
skipping: [schema-registry1] =&gt; (item={'logger_name': 'log4j.rootLogger', 'appenderRefs': 'file'})

TASK [confluent.platform.schema_registry : Restart schema registry] ************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Schema Registry Jolokia Config] ***
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Deploy JMX Exporter Config File] ****
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Basic Auth Jaas File] ********
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Basic Auth Password File] ****
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Create Service Override Directory] ***
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Write Service Overrides] ************
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Certs were Updated - Trigger Restart] ***
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : meta] *******************************

RUNNING HANDLER [confluent.platform.schema_registry : restart schema-registry] ***
included: /home/centos/repos/ansible_collections/confluent/platform/roles/schema_registry/tasks/restart_and_wait.yml for schema-registry1

RUNNING HANDLER [confluent.platform.schema_registry : Restart Schema Registry] ***
changed: [schema-registry1]

RUNNING HANDLER [confluent.platform.schema_registry : Startup Delay] ***********
ok: [schema-registry1]

TASK [confluent.platform.schema_registry : Start Schema Registry Service] ******
changed: [schema-registry1]

TASK [confluent.platform.schema_registry : Health Check] ***********************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/schema_registry/tasks/health_check.yml for schema-registry1

TASK [confluent.platform.schema_registry : Wait for API to return 200] *********
ok: [schema-registry1]

TASK [confluent.platform.schema_registry : Wait for API to return 200 - mTLS] ***
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Fetch Files for Debugging Failure] ***
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Fail Provisioning] ******************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Register Cluster] *******************
skipping: [schema-registry1]

TASK [confluent.platform.schema_registry : Delete temporary keys/certs when keystore and trustore is provided] ***
skipping: [schema-registry1] =&gt; (item=/var/ssl/private/ca.crt)
skipping: [schema-registry1] =&gt; (item=/var/ssl/private/schema_registry.crt)
skipping: [schema-registry1] =&gt; (item=/var/ssl/private/schema_registry.key)

TASK [Proceed Prompt] **********************************************************
skipping: [schema-registry1]

PLAY [Kafka Connect Status Finding] ********************************************

TASK [Populate service facts] **************************************************
ok: [kafka-connect1]

TASK [Determine Installation Pattern - Parallel or Serial] *********************
ok: [kafka-connect1]

TASK [Group Hosts by Installation Pattern] *************************************
ok: [kafka-connect1]

PLAY [Kafka Connect Parallel Provisioning] *************************************

TASK [include_role : common] ***************************************************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Gather OS Facts] **********************
ok: [kafka-connect1] =&gt; (item=ansible_os_family)
ok: [kafka-connect1] =&gt; (item=ansible_fqdn)

TASK [Stop Service and Remove Packages on Version Change] **********************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Install the Kafka Connect Packages] ***
skipping: [kafka-connect1] =&gt; (item=confluent-common)
skipping: [kafka-connect1] =&gt; (item=confluent-rest-utils)
skipping: [kafka-connect1] =&gt; (item=confluent-metadata-service)
skipping: [kafka-connect1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [kafka-connect1] =&gt; (item=confluent-kafka-rest)
skipping: [kafka-connect1] =&gt; (item=confluent-server-rest)
skipping: [kafka-connect1] =&gt; (item=confluent-telemetry)
skipping: [kafka-connect1] =&gt; (item=confluent-kafka)
skipping: [kafka-connect1] =&gt; (item=confluent-hub-client)
skipping: [kafka-connect1] =&gt; (item=confluent-kafka-connect-replicator)
skipping: [kafka-connect1] =&gt; (item=confluent-security)
skipping: [kafka-connect1] =&gt; (item=confluent-rebalancer)
skipping: [kafka-connect1] =&gt; (item=confluent-control-center-fe)
skipping: [kafka-connect1] =&gt; (item=confluent-control-center)
skipping: [kafka-connect1] =&gt; (item=confluent-schema-registry)

TASK [confluent.platform.kafka_connect : Install the Kafka Connect Packages] ***
skipping: [kafka-connect1] =&gt; (item=confluent-common)
skipping: [kafka-connect1] =&gt; (item=confluent-rest-utils)
skipping: [kafka-connect1] =&gt; (item=confluent-metadata-service)
skipping: [kafka-connect1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [kafka-connect1] =&gt; (item=confluent-kafka-rest)
skipping: [kafka-connect1] =&gt; (item=confluent-server-rest)
skipping: [kafka-connect1] =&gt; (item=confluent-telemetry)
skipping: [kafka-connect1] =&gt; (item=confluent-kafka)
skipping: [kafka-connect1] =&gt; (item=confluent-hub-client)
skipping: [kafka-connect1] =&gt; (item=confluent-kafka-connect-replicator)
skipping: [kafka-connect1] =&gt; (item=confluent-security)
skipping: [kafka-connect1] =&gt; (item=confluent-rebalancer)
skipping: [kafka-connect1] =&gt; (item=confluent-control-center-fe)
skipping: [kafka-connect1] =&gt; (item=confluent-control-center)
skipping: [kafka-connect1] =&gt; (item=confluent-schema-registry)

TASK [confluent.platform.kafka_connect : Create Kafka Connect Group] ***********
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Check if Kafka Connect User Exists] ***
ok: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Kafka Connect User] ************
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Copy Kafka Connect Service from archive file to system] ***
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Copy Kafka Connect Service from default install to system] ***
skipping: [kafka-connect1]

TASK [include_role : ssl] ******************************************************
skipping: [kafka-connect1]

TASK [Configure Kerberos] ******************************************************
skipping: [kafka-connect1]

TASK [Copy Kafka Connect Files] ************************************************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Configure RBAC] ***********************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Kafka Connect Config directory] ***
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Kafka Connect Config] **********
changed: [kafka-connect1]

TASK [Create Kafka Connect Config with Secrets Protection] *********************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Install Connect Plugins] **************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_connect/tasks/connect_plugins.yml for kafka-connect1

TASK [confluent.platform.kafka_connect : Ensure Plugin Dirs] *******************
changed: [kafka-connect1] =&gt; (item=/opt/confluent/confluent-7.2.2/share/java)
skipping: [kafka-connect1] =&gt; (item=/usr/share/java)

TASK [confluent.platform.kafka_connect : Installing Local Plugins] *************

TASK [confluent.platform.kafka_connect : Installing Remote Plugins] ************

TASK [confluent.platform.kafka_connect : Confluent Hub] ************************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Logs Directory] ****************
changed: [kafka-connect1]

TASK [Update Connect log4j Config for Log Cleanup] *****************************

TASK [confluent.platform.common : Replace rootLogger] **************************
changed: [kafka-connect1]

TASK [confluent.platform.common : Replace DailyRollingFileAppender with RollingFileAppender] ***
changed: [kafka-connect1]

TASK [confluent.platform.common : Remove Key log4j.appender.X.DatePattern] *****
changed: [kafka-connect1]

TASK [confluent.platform.common : Register Appenders] **************************
ok: [kafka-connect1]

TASK [confluent.platform.common : Add Max Size Properties] *********************
changed: [kafka-connect1] =&gt; (item=['connectAppender', 'Append=true'])
changed: [kafka-connect1] =&gt; (item=['connectAppender', 'MaxBackupIndex=10'])
changed: [kafka-connect1] =&gt; (item=['connectAppender', 'MaxFileSize=100MB'])

TASK [confluent.platform.kafka_connect : Set Permissions on Log4j Conf] ********
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create logredactor rule file directory] ***
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Copy logredactor rule file from control node to component node] ***
skipping: [kafka-connect1]

TASK [Configure logredactor] ***************************************************
skipping: [kafka-connect1] =&gt; (item={'logger_name': 'log4j.rootLogger', 'appenderRefs': 'connectAppender'})

TASK [confluent.platform.kafka_connect : Restart kafka connect] ****************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Kafka Connect Jolokia Config] ***
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Deploy JMX Exporter Config File] ******
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Basic Auth Jaas File] **********
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Basic Auth Password File] ******
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Create Service Override Directory] ****
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Write Service Overrides] **************
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Certs were Updated - Trigger Restart] ***
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : meta] *********************************

RUNNING HANDLER [confluent.platform.kafka_connect : restart connect distributed] ***
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_connect/tasks/restart_and_wait.yml for kafka-connect1

RUNNING HANDLER [confluent.platform.kafka_connect : Restart Kafka Connect] *****
changed: [kafka-connect1]

RUNNING HANDLER [confluent.platform.kafka_connect : Startup Delay] *************
ok: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Start Connect Service] ****************
changed: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Health Check] *************************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_connect/tasks/health_check.yml for kafka-connect1

TASK [confluent.platform.kafka_connect : Wait for API to return 200] ***********
ok: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Wait for API to return 200 - mTLS] ****
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Fetch Files for Debugging Failure] ****
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Fail Provisioning] ********************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Set parent Cluster] *******************
ok: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Register Cluster] *********************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_connect/tasks/register_cluster.yml for kafka-connect1

TASK [confluent.platform.common : Get Kafka Cluster ID from Embedded Rest Proxy] ***
skipping: [kafka-connect1]

TASK [confluent.platform.common : Parse Kafka Cluster ID from json query] ******
skipping: [kafka-connect1]

TASK [confluent.platform.common : Get Kafka Cluster ID from Zookeeper] *********
skipping: [kafka-connect1]

TASK [confluent.platform.common : set_fact] ************************************
skipping: [kafka-connect1]

TASK [confluent.platform.common : Set kafka_cluster_id Variable] ***************
skipping: [kafka-connect1]

TASK [confluent.platform.common : Create SSL Certificate Directory] ************
skipping: [kafka-connect1]

TASK [confluent.platform.common : Check if MDS public pem file exists on Ansible Controller] ***
skipping: [kafka-connect1]

TASK [confluent.platform.common : Debug] ***************************************
skipping: [kafka-connect1]

TASK [confluent.platform.common : Copy in MDS Public Pem File] *****************
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Fetch Kafka Connect Cluster Groups] ***
ok: [kafka-connect1] =&gt; (item=kafka-connect1)

TASK [confluent.platform.kafka_connect : Register Kafka Connect Cluster] *******
skipping: [kafka-connect1] =&gt; (item=kafka-connect1)

TASK [confluent.platform.kafka_connect : Deploy Connectors] ********************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_connect/tasks/deploy_connectors.yml for kafka-connect1

TASK [confluent.platform.kafka_connect : Register Kafka Connect Subgroups] *****
ok: [kafka-connect1] =&gt; (item=kafka-connect1)

TASK [confluent.platform.kafka_connect : Register connector configs and remove deleted connectors for single cluster] ***
skipping: [kafka-connect1]

TASK [confluent.platform.kafka_connect : Register connector configs and remove deleted connectors for Multiple Clusters] ***

TASK [confluent.platform.kafka_connect : Delete temporary keys/certs when keystore and trustore is provided] ***
skipping: [kafka-connect1] =&gt; (item=/var/ssl/private/ca.crt)
skipping: [kafka-connect1] =&gt; (item=/var/ssl/private/kafka_connect.crt)
skipping: [kafka-connect1] =&gt; (item=/var/ssl/private/kafka_connect.key)
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_serial

PLAY [Kafka Connect Serial Provisioning] ***************************************
skipping: no hosts matched

PLAY [KSQL Status Finding] *****************************************************

TASK [Populate service facts] **************************************************
ok: [ksql1]

TASK [Determine Installation Pattern - Parallel or Serial] *********************
ok: [ksql1]

TASK [Group Hosts by Installation Pattern] *************************************
ok: [ksql1]

PLAY [KSQL Parallel Provisioning] **********************************************

TASK [include_role : common] ***************************************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Gather OS Facts] *******************************
ok: [ksql1] =&gt; (item=ansible_os_family)
ok: [ksql1] =&gt; (item=ansible_fqdn)

TASK [Stop Service and Remove Packages on Version Change] **********************
skipping: [ksql1]

TASK [confluent.platform.ksql : Install the Ksql Packages] *********************
skipping: [ksql1] =&gt; (item=confluent-common)
skipping: [ksql1] =&gt; (item=confluent-rest-utils)
skipping: [ksql1] =&gt; (item=confluent-metadata-service)
skipping: [ksql1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [ksql1] =&gt; (item=confluent-kafka-rest)
skipping: [ksql1] =&gt; (item=confluent-server-rest)
skipping: [ksql1] =&gt; (item=confluent-telemetry)
skipping: [ksql1] =&gt; (item=confluent-kafka)
skipping: [ksql1] =&gt; (item=confluent-ksqldb)
skipping: [ksql1] =&gt; (item=confluent-security)
skipping: [ksql1] =&gt; (item=confluent-rebalancer)
skipping: [ksql1] =&gt; (item=confluent-control-center-fe)
skipping: [ksql1] =&gt; (item=confluent-control-center)

TASK [confluent.platform.ksql : Install the Ksql Packages] *********************
skipping: [ksql1] =&gt; (item=confluent-common)
skipping: [ksql1] =&gt; (item=confluent-rest-utils)
skipping: [ksql1] =&gt; (item=confluent-metadata-service)
skipping: [ksql1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [ksql1] =&gt; (item=confluent-kafka-rest)
skipping: [ksql1] =&gt; (item=confluent-server-rest)
skipping: [ksql1] =&gt; (item=confluent-telemetry)
skipping: [ksql1] =&gt; (item=confluent-kafka)
skipping: [ksql1] =&gt; (item=confluent-ksqldb)
skipping: [ksql1] =&gt; (item=confluent-security)
skipping: [ksql1] =&gt; (item=confluent-rebalancer)
skipping: [ksql1] =&gt; (item=confluent-control-center-fe)
skipping: [ksql1] =&gt; (item=confluent-control-center)

TASK [confluent.platform.ksql : Create Ksql Group] *****************************
changed: [ksql1]

TASK [confluent.platform.ksql : Check if Ksql User Exists] *********************
ok: [ksql1]

TASK [confluent.platform.ksql : Create Ksql User] ******************************
changed: [ksql1]

TASK [confluent.platform.ksql : Set Ksql streams dir permissions] **************
changed: [ksql1]

TASK [confluent.platform.ksql : Copy Ksql Service from archive file to system] ***
changed: [ksql1]

TASK [include_role : ssl] ******************************************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Import Public Confluent Cloud Certificates Authority Certs into Truststore] ***
skipping: [ksql1]

TASK [Configure Kerberos] ******************************************************
skipping: [ksql1]

TASK [Copy Custom KSQL Files] **************************************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Configure RBAC] ********************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create Ksql Config directory] ******************
changed: [ksql1]

TASK [confluent.platform.ksql : Create Ksql Config] ****************************
changed: [ksql1]

TASK [Create Ksql Config with Secrets Protection] ******************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create Logs Directory] *************************
changed: [ksql1]

TASK [confluent.platform.ksql : Create log4j Directory] ************************
changed: [ksql1]

TASK [confluent.platform.ksql : Create Ksql log4j Config] **********************
changed: [ksql1]

TASK [confluent.platform.ksql : Create logredactor rule file directory] ********
skipping: [ksql1]

TASK [confluent.platform.ksql : Copy logredactor rule file from control node to component node] ***
skipping: [ksql1]

TASK [Configure logredactor] ***************************************************
skipping: [ksql1] =&gt; (item={'logger_name': 'log4j.rootLogger', 'appenderRefs': 'main'})

TASK [confluent.platform.ksql : Restart ksql] **********************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create Ksql Jolokia Config] ********************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create RocksDB Directory] **********************
changed: [ksql1]

TASK [confluent.platform.ksql : Set Permission to RocksDB Files] ***************
ok: [ksql1]

TASK [confluent.platform.ksql : Deploy JMX Exporter Config File] ***************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create Basic Auth Jaas File] *******************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create Basic Auth Password File] ***************
skipping: [ksql1]

TASK [confluent.platform.ksql : Create Service Override Directory] *************
changed: [ksql1]

TASK [confluent.platform.ksql : Write Service Overrides] ***********************
changed: [ksql1]

TASK [confluent.platform.ksql : Certs were Updated - Trigger Restart] **********
skipping: [ksql1]

TASK [confluent.platform.ksql : meta] ******************************************

RUNNING HANDLER [confluent.platform.ksql : restart ksql] ***********************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/ksql/tasks/restart_and_wait.yml for ksql1

RUNNING HANDLER [confluent.platform.ksql : Restart KSQL] ***********************
changed: [ksql1]

RUNNING HANDLER [confluent.platform.ksql : Startup Delay] **********************
ok: [ksql1]

TASK [confluent.platform.ksql : Start Ksql Service] ****************************
changed: [ksql1]

TASK [confluent.platform.ksql : Health Check] **********************************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/ksql/tasks/health_check.yml for ksql1

TASK [confluent.platform.ksql : Wait for API to return 200] ********************
ok: [ksql1]

TASK [confluent.platform.ksql : Wait for API to return 200 - mTLS] *************
skipping: [ksql1]

TASK [confluent.platform.ksql : Fetch Files for Debugging Failure] *************
skipping: [ksql1]

TASK [confluent.platform.ksql : Fail Provisioning] *****************************
skipping: [ksql1]

TASK [confluent.platform.ksql : Set parent Cluster] ****************************
ok: [ksql1]

TASK [confluent.platform.ksql : Register Cluster] ******************************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/ksql/tasks/register_cluster.yml for ksql1

TASK [confluent.platform.common : Get Kafka Cluster ID from Embedded Rest Proxy] ***
skipping: [ksql1]

TASK [confluent.platform.common : Parse Kafka Cluster ID from json query] ******
skipping: [ksql1]

TASK [confluent.platform.common : Get Kafka Cluster ID from Zookeeper] *********
skipping: [ksql1]

TASK [confluent.platform.common : set_fact] ************************************
skipping: [ksql1]

TASK [confluent.platform.common : Set kafka_cluster_id Variable] ***************
skipping: [ksql1]

TASK [confluent.platform.common : Create SSL Certificate Directory] ************
skipping: [ksql1]

TASK [confluent.platform.common : Check if MDS public pem file exists on Ansible Controller] ***
skipping: [ksql1]

TASK [confluent.platform.common : Debug] ***************************************
skipping: [ksql1]

TASK [confluent.platform.common : Copy in MDS Public Pem File] *****************
skipping: [ksql1]

TASK [confluent.platform.ksql : Fetch KSQL Cluster Groups] *********************
ok: [ksql1] =&gt; (item=ksql1)

TASK [confluent.platform.ksql : Register KSQL Cluster] *************************
skipping: [ksql1] =&gt; (item=ksql1)

TASK [confluent.platform.ksql : Delete temporary keys/certs when keystore and trustore is provided] ***
skipping: [ksql1] =&gt; (item=/var/ssl/private/ca.crt)
skipping: [ksql1] =&gt; (item=/var/ssl/private/ksql.crt)
skipping: [ksql1] =&gt; (item=/var/ssl/private/ksql.key)
[WARNING]: Could not match supplied host pattern, ignoring: ksql_serial

PLAY [KSQL Serial Provisioning] ************************************************
skipping: no hosts matched

PLAY [Kafka Rest Status Finding] ***********************************************

TASK [Populate service facts] **************************************************
ok: [kafka-rest1]

TASK [Determine Installation Pattern - Parallel or Serial] *********************
ok: [kafka-rest1]

TASK [Group Hosts by Installation Pattern] *************************************
ok: [kafka-rest1]

PLAY [Kafka Rest Parallel Provisioning] ****************************************

TASK [include_role : common] ***************************************************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Gather OS Facts] *************************
ok: [kafka-rest1] =&gt; (item=ansible_os_family)
ok: [kafka-rest1] =&gt; (item=ansible_fqdn)

TASK [Stop Service and Remove Packages on Version Change] **********************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Install the Kafka Rest Packages] *********
skipping: [kafka-rest1] =&gt; (item=confluent-common)
skipping: [kafka-rest1] =&gt; (item=confluent-rest-utils)
skipping: [kafka-rest1] =&gt; (item=confluent-metadata-service)
skipping: [kafka-rest1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [kafka-rest1] =&gt; (item=confluent-kafka-rest)
skipping: [kafka-rest1] =&gt; (item=confluent-server-rest)
skipping: [kafka-rest1] =&gt; (item=confluent-telemetry)
skipping: [kafka-rest1] =&gt; (item=confluent-kafka)
skipping: [kafka-rest1] =&gt; (item=confluent-security)
skipping: [kafka-rest1] =&gt; (item=confluent-rebalancer)
skipping: [kafka-rest1] =&gt; (item=confluent-control-center-fe)
skipping: [kafka-rest1] =&gt; (item=confluent-control-center)

TASK [confluent.platform.kafka_rest : Install the Kafka Rest Packages] *********
skipping: [kafka-rest1] =&gt; (item=confluent-common)
skipping: [kafka-rest1] =&gt; (item=confluent-rest-utils)
skipping: [kafka-rest1] =&gt; (item=confluent-metadata-service)
skipping: [kafka-rest1] =&gt; (item=confluent-ce-kafka-http-server)
skipping: [kafka-rest1] =&gt; (item=confluent-kafka-rest)
skipping: [kafka-rest1] =&gt; (item=confluent-server-rest)
skipping: [kafka-rest1] =&gt; (item=confluent-telemetry)
skipping: [kafka-rest1] =&gt; (item=confluent-kafka)
skipping: [kafka-rest1] =&gt; (item=confluent-security)
skipping: [kafka-rest1] =&gt; (item=confluent-rebalancer)
skipping: [kafka-rest1] =&gt; (item=confluent-control-center-fe)
skipping: [kafka-rest1] =&gt; (item=confluent-control-center)

TASK [confluent.platform.kafka_rest : Create Kafka Rest Group] *****************
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Check if Kafka Rest User Exists] *********
ok: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Kafka Rest User] ******************
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Copy Kafka Rest Service from archive file to system] ***
changed: [kafka-rest1]

TASK [include_role : ssl] ******************************************************
skipping: [kafka-rest1]

TASK [Configure Kerberos] ******************************************************
skipping: [kafka-rest1]

TASK [Copy Custom Kafka Rest Files] ********************************************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Configure RBAC] **************************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create SSL Certificate Directory] ********
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Check if MDS public pem file exists on Ansible Controller] ***
ok: [kafka-rest1 -&gt; localhost]

TASK [confluent.platform.kafka_rest : Debug] ***********************************
ok: [kafka-rest1] =&gt; {
    "msg": "WARNING - The file generated_ssl_files/public.pem doesn't exist on the control node"
}

TASK [confluent.platform.kafka_rest : Copy in MDS Public Pem File] *************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Kafka Rest Config directory] ******
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Kafka Rest Config] ****************
changed: [kafka-rest1]

TASK [Create Kafka Rest Config with Secrets Protection] ************************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Logs Directory] *******************
changed: [kafka-rest1]

TASK [Update log4j Config for Log Cleanup] *************************************

TASK [confluent.platform.common : Replace rootLogger] **************************
ok: [kafka-rest1]

TASK [confluent.platform.common : Replace DailyRollingFileAppender with RollingFileAppender] ***
ok: [kafka-rest1]

TASK [confluent.platform.common : Remove Key log4j.appender.X.DatePattern] *****
ok: [kafka-rest1]

TASK [confluent.platform.common : Register Appenders] **************************
ok: [kafka-rest1]

TASK [confluent.platform.common : Add Max Size Properties] *********************
changed: [kafka-rest1] =&gt; (item=['file', 'Append=true'])
changed: [kafka-rest1] =&gt; (item=['file', 'MaxBackupIndex=10'])
changed: [kafka-rest1] =&gt; (item=['file', 'MaxFileSize=100MB'])

TASK [confluent.platform.kafka_rest : Set Permissions on Log4j Conf] ***********
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create logredactor rule file directory] ***
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Copy logredactor rule file from control node to component node] ***
skipping: [kafka-rest1]

TASK [Configure logredactor] ***************************************************
skipping: [kafka-rest1] =&gt; (item={'logger_name': 'log4j.rootLogger', 'appenderRefs': 'file'})

TASK [confluent.platform.kafka_rest : Restart kafka rest] **********************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Kafka Rest Jolokia Config] ********
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Deploy JMX Exporter Config File] *********
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Basic Auth Jaas File] *************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Basic Auth Password File] *********
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Create Service Override Directory] *******
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Write Service Overrides] *****************
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Certs were Updated - Trigger Restart] ****
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : meta] ************************************

RUNNING HANDLER [confluent.platform.kafka_rest : restart kafka-rest] ***********
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_rest/tasks/restart_and_wait.yml for kafka-rest1

RUNNING HANDLER [confluent.platform.kafka_rest : Restart Kafka Rest] ***********
changed: [kafka-rest1]

RUNNING HANDLER [confluent.platform.kafka_rest : Startup Delay] ****************
ok: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Start Kafka Rest Service] ****************
changed: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Health Check] ****************************
included: /home/centos/repos/ansible_collections/confluent/platform/roles/kafka_rest/tasks/health_check.yml for kafka-rest1

TASK [confluent.platform.kafka_rest : Wait for API to return 200] **************
ok: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Wait for API to return 200 - mTLS] *******
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Fetch Files for Debugging Failure] *******
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Fail Provisioning] ***********************
skipping: [kafka-rest1]

TASK [confluent.platform.kafka_rest : Delete temporary keys/certs when keystore and trustore is provided] ***
skipping: [kafka-rest1] =&gt; (item=/var/ssl/private/ca.crt)
skipping: [kafka-rest1] =&gt; (item=/var/ssl/private/kafka_rest.crt)
skipping: [kafka-rest1] =&gt; (item=/var/ssl/private/kafka_rest.key)
[WARNING]: Could not match supplied host pattern, ignoring: kafka_rest_serial

PLAY [Kafka Rest Serial Provisioning] ******************************************
skipping: no hosts matched

PLAY [Control Center Status Finding] *******************************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring:
control_center_parallel

PLAY [Control Center Parallel Provisioning] ************************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring:
control_center_serial

PLAY [Control Center Serial Provisioning] **************************************
skipping: no hosts matched

PLAY [Kafka Connect Replicator Status Finding] *********************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_replicator_parallel

PLAY [Kafka Connect Replicator Parallel Provisioning] **************************
skipping: no hosts matched
[WARNING]: Could not match supplied host pattern, ignoring:
kafka_connect_replicator_serial

PLAY [Kafka Connect Replicator Serial Provisioning] ****************************
skipping: no hosts matched

PLAY RECAP *********************************************************************
kafka-broker1              : ok=54   changed=24   unreachable=0    failed=0    skipped=59   rescued=0    ignored=0
kafka-connect1             : ok=54   changed=22   unreachable=0    failed=0    skipped=65   rescued=0    ignored=0
kafka-rest1                : ok=49   changed=18   unreachable=0    failed=0    skipped=51   rescued=0    ignored=0
ksql1                      : ok=49   changed=20   unreachable=0    failed=0    skipped=60   rescued=0    ignored=0
schema-registry1           : ok=44   changed=18   unreachable=0    failed=0    skipped=51   rescued=0    ignored=0
zookeeper1                 : ok=47   changed=20   unreachable=0    failed=0    skipped=48   rescued=0    ignored=0

INFO     Running archive-community-plaintext-rhel &gt; side_effect
WARNING  Skipping, side effect playbook not configured.
INFO     Running archive-community-plaintext-rhel &gt; verify
INFO     Running Ansible Verifier
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[WARNING]: running playbook inside collection confluent.platform

PLAY [Verify - Confluent CLI] **************************************************

TASK [Check confluent cli is installed] ****************************************
changed: [kafka-broker1]
changed: [zookeeper1]
changed: [kafka-rest1]
changed: [ksql1]
changed: [schema-registry1]
changed: [kafka-connect1]

PLAY RECAP *********************************************************************
kafka-broker1              : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
kafka-connect1             : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
kafka-rest1                : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
ksql1                      : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
schema-registry1           : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
zookeeper1                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

INFO     Verifier completed successfully.
INFO     Running archive-community-plaintext-rhel &gt; cleanup
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
[WARNING]: running playbook inside collection confluent.platform

PLAY [Cleanup] *****************************************************************

TASK [Delete Tar Jar] **********************************************************
changed: [localhost]

TASK [Delete Tar CLI] **********************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

INFO     Running archive-community-plaintext-rhel &gt; destroy
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the
controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 16
2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]. This feature will be
removed from ansible-core in version 2.12. Deprecation warnings can be disabled
 by setting deprecation_warnings=False in ansible.cfg.

PLAY [Destroy] *****************************************************************

TASK [Destroy molecule instance(s)] ********************************************
/home/centos/.local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
  from cryptography.exceptions import InvalidSignature
changed: [localhost] =&gt; (item=zookeeper1)
changed: [localhost] =&gt; (item=kafka-broker1)
changed: [localhost] =&gt; (item=schema-registry1)
changed: [localhost] =&gt; (item=kafka-rest1)
changed: [localhost] =&gt; (item=kafka-connect1)
changed: [localhost] =&gt; (item=ksql1)

TASK [Wait for instance(s) deletion to complete] *******************************
changed: [localhost] =&gt; (item=zookeeper1)
changed: [localhost] =&gt; (item=kafka-broker1)
changed: [localhost] =&gt; (item=schema-registry1)
changed: [localhost] =&gt; (item=kafka-rest1)
changed: [localhost] =&gt; (item=kafka-connect1)
changed: [localhost] =&gt; (item=ksql1)

TASK [Delete docker networks(s)] ***********************************************
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)
included: /home/centos/.local/lib/python3.6/site-packages/molecule_docker/playbooks/tasks/delete_network.yml for localhost =&gt; (item=confluent)

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
changed: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

TASK [Retrieve network info] ***************************************************
ok: [localhost]

TASK [Delete docker network(s)] ************************************************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=15   changed=3    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0

INFO     Pruning extra files from scenario ephemeral directory

</system-out></testcase></testsuite></testsuites>